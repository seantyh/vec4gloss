{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254163df-d703-433b-905b-b29ef6450d88",
   "metadata": {},
   "source": [
    "# Decoding Logits - Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95881a3-099e-4d42-af89-84af18de1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051d63a6-dee0-45eb-941f-3de815f47dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import MT5TokenizerFast\n",
    "from vec4gloss import check_hashes\n",
    "from vec4gloss import Vec4GlossModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4797a1ba-0348-46a3-a12f-d055e923ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CwnGraph import CwnImage\n",
    "cwn = CwnImage.latest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a77085b-b3be-4114-ba59-44a1d70e6abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and \"GeForce\" not in torch.cuda.get_device_name():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6667235-fb01-4c60-8900-2b10200bde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "ds_defgen = datasets.load_from_disk(\"../data/defgen_dataset_cwn\")\n",
    "vec4gloss_model_dir = \"../data/models/vec4gloss-defgen-220629-1250\"\n",
    "model = Vec4GlossModel.from_pretrained(vec4gloss_model_dir).to(device)\n",
    "tokenizer = MT5TokenizerFast.from_pretrained(vec4gloss_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37942b76-3827-4283-bb66-d7b161ee8780",
   "metadata": {},
   "source": [
    "## Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa2bab9-b020-412b-8019-1bc1f83a3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "\n",
    "def get_marked_pos(text):\n",
    "    assert text.count(\"<\") == text.count(\">\") == 1\n",
    "    s, e = text.index(\"<\")+1, text.index(\">\")    \n",
    "    assert s != e\n",
    "    return s, e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db4fd9-90bf-4cac-b3e1-89e5d047e8e5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "112f5933-46d0-47de-996e-6e2cfa863400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_encoder_vector(intext, tokenizer, model):    \n",
    "    vbatch = tokenizer(intext, return_tensors=\"pt\").to(model.device)\n",
    "    s,e = get_marked_pos(intext)   \n",
    "    s = vbatch.char_to_token(s)\n",
    "    e = vbatch.char_to_token(e)\n",
    "    vbatch[\"decoder_start_markers\"] = torch.tensor([s]).to(model.device)\n",
    "    vbatch[\"decoder_end_markers\"] = torch.tensor([e]).to(model.device)\n",
    "    encoder = model.get_encoder()\n",
    "    enc_out = encoder(\n",
    "            input_ids=vbatch[\"input_ids\"], \n",
    "            attention_mask=vbatch[\"attention_mask\"])\n",
    "    enc_vec = enc_out.last_hidden_state[[0],s:e,:] \\\n",
    "                     .mean(1, keepdim=True)\n",
    "    return enc_vec\n",
    "\n",
    "def decode_vector(vec, tokenizer, model, max_length=50):\n",
    "    vgenout = model.generate(decoder_encoder_vector=vec, bos_token_id=0, max_length=max_length)\n",
    "    return tokenizer.batch_decode(vgenout[:, 1:-1])[0]\n",
    "\n",
    "def gen_func(tokenizer, model):\n",
    "    def _gen_func(text):\n",
    "        enc_vec = extract_encoder_vector(text, tokenizer, model)\n",
    "        return decode_vector(enc_vec, tokenizer, model)\n",
    "    return _gen_func\n",
    "gen = gen_func(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4d58d-1ac1-4c48-945d-95221729cc75",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3724f4-baff-4482-b166-00189ad9a6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VC。比喻用特定方式使特定對象受到損害。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"我line他都不回我，我被<塑膠>了。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "740d8ac5-29b5-4a9a-a044-ae928dc36458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VC。進行會議。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"周杰倫今天召<開>演唱會很開心。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b02896f-bc35-4cf7-8a44-a7e91d81a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VK。形容在意料之外意識到後述事件的存在。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"我赫然<驚覺>我忘了。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80ec26a-5b55-4cec-8851-fc0426aa7a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D。表共同做。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"昨天大家好不容易<團約>上陽明山。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6f1b4a-9de8-425e-8fd2-e386e1625877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VE。經過思考後決定。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"我<確認過眼神>，今天的數學考卷很難，完蛋了！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66f18360-9916-448d-b9de-969eb616eb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<CwnSense[07033703](驚，VK): 在意料之外意識到後述事件的存在。>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwn.find_senses(definition=\"意識到後述事件的存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14f646-9c44-43c0-b81b-34433616c682",
   "metadata": {},
   "source": [
    "## Vector morphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0718447e-ebf5-4cd6-a1fd-d93b4fd7a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 Na。植物的主要器官之一,主要用於繁殖,通常具有顏色鮮豔和形狀漂亮的花瓣。\n",
      "0.20 Na。植物名,薔薇科櫻屬,多年生草本,葉呈長橢圓形,有花瓣五片,有粉紅、白、紅等顏色。\n",
      "0.40 Na。植物名,薔薇科櫻屬,多年生草本,葉呈長橢圓形,有花瓣五片,有粉紅、白、紅等顏色。\n",
      "0.60 Na。書寫筆畫的一種,由左向右上斜的筆畫。\n",
      "0.80 Na。筆畫的一種,由左向右上斜的筆畫。\n",
      "1.00 Nf。計算筆畫的單位。\n"
     ]
    }
   ],
   "source": [
    "enc_vec1 = extract_encoder_vector(\"那是一位嬌豔如<花>的少女。\", tokenizer, model)\n",
    "enc_vec2 = extract_encoder_vector(\"以動畫方式慢速地顯示字母的每一<筆>一劃。\", tokenizer, model)\n",
    "delta = enc_vec2 - enc_vec1\n",
    "for i in np.arange(0, 1.01, 0.2):\n",
    "    print(f\"{i:.2f}\", decode_vector(enc_vec1+delta*i, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae610abe-c8c4-4867-9765-9af25233699a",
   "metadata": {},
   "source": [
    "## Vector perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00441e04-d95d-4558-a7c8-59ded3dc82ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na。魚類的通稱,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,趾尖呈鱗狀,肉質鮮美\n",
      "Na。魚類的通稱。\n",
      "Na。魚類的通稱,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗狀,鱗\n",
      "Na。用來釣魚的一種技巧,用來輔助釣魚的技巧。\n",
      "Na。用來魚類的魚類,形狀似魚,體型細長,外型稍微小,外型稍微細,味酸可食,可醃製成多種蜜餞。\n",
      "Na。常綠或落葉灌木,葉子橢圓形,春夏開花,有粉紅、白、紅等顏色,果實球形,味酸可食,可醃製成多種蜜\n",
      "Na。落葉喬木,葉卵形,早春開花,花瓣五片,有粉紅、白、紅等顏色,果實球形,味酸可食,可醃製成多種\n",
      "Na。以魚為形象製成的人造物。\n",
      "Na。魚類的通稱。\n",
      "Na。魚類身上用來釣魚的纖維。\n"
     ]
    }
   ],
   "source": [
    "enc_vec = extract_encoder_vector(\"蘇打綠改名成<魚丁糸>\", tokenizer, model)\n",
    "for _ in range(10):\n",
    "    rand_vec = torch.randn(768).to(device)\n",
    "    print(decode_vector(enc_vec+rand_vec*0.04, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67b7000c-1e70-48cf-beba-3f6d7e3c75d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 VH。形容比喻具有不合乎常理的特質。\n",
      "0.01 VH。形容比喻具有不合乎常理的特質。\n",
      "0.02 VH。形容比喻個性急躁的。\n",
      "0.03 VH。形容比喻對特定對象有負面的經驗與感覺。\n",
      "0.04 VH。形容比喻具有過度執照、不善言辭的。\n",
      "0.05 VH。形容比喻態度惡劣的。\n",
      "0.06 VH。形容比喻不具有美的特質。\n",
      "0.07 VH。形容比喻具有外在特質的。\n",
      "0.08 VH。形容比喻對思想或立場不專注的。\n",
      "0.09 VH。形容比喻耗費耗費特定經濟能量的。\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12353)\n",
    "enc_vec = extract_encoder_vector(\"他這個人很<塑膠>\", tokenizer, model)\n",
    "for scale in range(0, 10, 1):\n",
    "    rand_vec = torch.randn(768).to(device)\n",
    "    print(f\"{scale/100:.2f}\", decode_vector(enc_vec+rand_vec*scale/100, tokenizer, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
