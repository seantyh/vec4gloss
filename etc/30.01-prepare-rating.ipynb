{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44f67d8-2f95-46c5-a584-3f3d01595f11",
   "metadata": {},
   "source": [
    "# Prepare Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661bf2ca-b8a7-47a8-8965-8ad5702defa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.append(\"../src\")\n",
    "if \"../../pyASBC/src\" not in sys.path:\n",
    "    sys.path.append(\"../../pyASBC/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af613c3b-6d89-43e7-8c93-6024ade42d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from itertools import islice, chain, groupby\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import MT5TokenizerFast\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import datasets\n",
    "\n",
    "from CwnGraph import CwnImage\n",
    "import vec4gloss\n",
    "from vec4gloss import check_hashes\n",
    "from vec4gloss import Vec4GlossModel\n",
    "from pyASBC import Asbc5Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad996d0b-4182-48d4-bbb8-33147a6cca9a",
   "metadata": {},
   "source": [
    "## Data dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df370cdb-8678-4308-b6ec-b837eb231873",
   "metadata": {},
   "source": [
    "```\n",
    "10.11 -> ..\\data\\defgen_dataset_cwn\\train\\dataset.arrow 65a56d\n",
    "20.21 -> ..\\data\\models\\vec4gloss-defgen-220629-1250\\pytorch_model.bin 9f894f\n",
    "(external) -> ..\\data\\asbc5_words_pos.pkl 70badc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a101b0d-1e45-4ecf-a818-b02e407f1223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\defgen_dataset_cwn\\train\\dataset.arrow 65a56d\n",
      "..\\data\\models\\vec4gloss-defgen-220629-1250\\pytorch_model.bin 9f894f\n",
      "..\\data\\asbc5_words_pos.pkl 70badc\n"
     ]
    }
   ],
   "source": [
    "vec4gloss_model_dir = \"../data/models/vec4gloss-defgen-220629-1250\"\n",
    "_ = check_hashes([\n",
    "    \"../data/defgen_dataset_cwn/train/dataset.arrow\",\n",
    "    vec4gloss_model_dir + \"/pytorch_model.bin\",\n",
    "    \"../data/asbc5_words_pos.pkl\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bfa651-97f8-49ef-a61e-84ed69f74b3b",
   "metadata": {},
   "source": [
    "## Loading resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8df1d5c-cff5-4ff6-bff2-d468f059af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/asbc5_words_pos.pkl\", \"rb\") as fin:\n",
    "    asbc_words = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d266e3-eaac-40df-94a6-11f5add4ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and \"GeForce\" not in torch.cuda.get_device_name():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f42cd71-0c3f-430a-b1d9-f2a148455950",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_defgen = datasets.load_from_disk(\"../data/defgen_dataset_cwn\")\n",
    "model = Vec4GlossModel.from_pretrained(vec4gloss_model_dir).to(device)\n",
    "tokenizer = MT5TokenizerFast.from_pretrained(vec4gloss_model_dir)\n",
    "gen = vec4gloss.gen_func(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55960220-8cd3-4a1b-903a-45631a53b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWN_VER = \"v.2022.06.21\"\n",
    "cwn = CwnImage.load(CWN_VER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ca527-01a4-4516-b2ea-810aa7df8f7c",
   "metadata": {},
   "source": [
    "## Prepare rating materials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15123cc-6820-4d49-90ee-77b2aab6a314",
   "metadata": {},
   "source": [
    "### New words from ASBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cf9b0e-a49f-4eff-b1ed-08882b49d54f",
   "metadata": {},
   "source": [
    "* frequency > 10\n",
    "* no proper nouns (Nb)\n",
    "* only words composed of Chinese characters(U+4E00-U+9FFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48230bd-e8c7-4afe-84ba-301c99d49941",
   "metadata": {},
   "outputs": [],
   "source": [
    "asbc = Asbc5Corpus(\"../../pyASBC/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9afd72-8b1d-4e6f-a0f7-fd68a93f6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_example_sentence(target, pos):\n",
    "    for sent in asbc.iter_sentences():        \n",
    "        tgt_idx = [i for i, (w,p,_)\n",
    "                   in enumerate(sent)\n",
    "                   if w==target and p==pos]\n",
    "        if tgt_idx:            \n",
    "            tgt_idx = tgt_idx[0]\n",
    "            words = [x[0] for x in sent]\n",
    "            words[tgt_idx] = f\"<{target}>\"\n",
    "            return \"\".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24818e19-7638-4bab-b6c4-0304f17a6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_asbc = random.Random(14434)\n",
    "lemmas = set(cwn.get_all_lemmas().keys())\n",
    "chpat = re.compile(\"^[\\u4e00-\\u9fff]+$\")\n",
    "asbc_pos_list = {\"D\": [], \"N\": [], \"V\": [], \"O\": []}\n",
    "for (word, pos), freq in asbc_words.most_common():\n",
    "    if freq < 20: continue\n",
    "    if pos == \"Nb\": continue\n",
    "    if not chpat.match(word): continue\n",
    "    if word not in lemmas:\n",
    "        if pos and pos[0] in \"DVN\":\n",
    "            poscat = pos[0]\n",
    "        else:\n",
    "            poscat = \"O\"\n",
    "        asbc_pos_list[poscat].append((word, pos))\n",
    "for poscat in asbc_pos_list:\n",
    "    rng_asbc.shuffle(asbc_pos_list[poscat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8dca169-c244-459b-a8c1-f909cb8f2adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 285, 'N': 6396, 'V': 4032, 'O': 135}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(v) for k, v in asbc_pos_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb891bcf-1a6e-4e26-8863-0c9520212f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e523b5f5671b4ee189a1fe350528c443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_words = {\"D\": [], \"N\": [], \"V\": [], \"O\": []}\n",
    "pbar = tqdm(total=20)\n",
    "for poscat, pos_buf in new_words.items():\n",
    "    word_list = asbc_pos_list[poscat][::-1]\n",
    "    while len(pos_buf) < 5:        \n",
    "        pbar.update(1)\n",
    "        entry_x = {}\n",
    "        word, pos = word_list.pop()\n",
    "        entry_x[\"from\"] = \"ASBC\"\n",
    "        entry_x[\"pos\"] = poscat\n",
    "        entry_x[\"target\"] = word\n",
    "        entry_x[\"fillers\"] = [word_list.pop()[0] for _ in range(3)]\n",
    "        sent = find_example_sentence(word, pos)        \n",
    "        if not sent:\n",
    "            continue\n",
    "            \n",
    "        deftext = gen(sent).split(\"。\")[1]\n",
    "        if not deftext.endswith(\"。\"):\n",
    "            deftext += \"。\"\n",
    "        deftext = deftext.translate(str.maketrans(\",.\", \"，。\"))\n",
    "        entry_x[\"definition\"] = deftext\n",
    "        entry_x[\"item_id\"] = f\"{poscat}-{(len(pos_buf)+50):02d}\"\n",
    "        pos_buf.append(entry_x)        \n",
    "pbar.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827bd857-a125-4e34-9311-623d2f1db0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': {'from': 'ASBC',\n",
       "  'pos': 'D',\n",
       "  'target': '一窩蜂',\n",
       "  'fillers': ['何妨', '同聲', '方才'],\n",
       "  'definition': '比喻嗜好特定對象的怪獸。',\n",
       "  'item_id': 'D-50'},\n",
       " 'N': {'from': 'ASBC',\n",
       "  'pos': 'N',\n",
       "  'target': '明牌',\n",
       "  'fillers': ['西湖', '小生', '磚牆'],\n",
       "  'definition': '比喻在競爭中被淘汰的對象。',\n",
       "  'item_id': 'N-50'},\n",
       " 'V': {'from': 'ASBC',\n",
       "  'pos': 'V',\n",
       "  'target': '刺進',\n",
       "  'fillers': ['放生', '燃起', '與日俱增'],\n",
       "  'definition': '物體表面或特定部位向外凸出。',\n",
       "  'item_id': 'V-50'},\n",
       " 'O': {'from': 'ASBC',\n",
       "  'pos': 'O',\n",
       "  'target': '長足',\n",
       "  'fillers': ['麻辣', '英屬', '駐華'],\n",
       "  'definition': '比喻事件發展的基礎。',\n",
       "  'item_id': 'O-50'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v[0] for k, v in new_words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0026a2d2-7b70-4e7e-baa1-a80a634b56cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 5), ('N', 5), ('V', 5), ('O', 5)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], len(x[1])) for x in new_words.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e90629-a9c1-4f19-9c4f-bb54a10365fd",
   "metadata": {},
   "source": [
    "### Words in evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188353e7-0e8f-47f7-bee9-9049bb2e34e2",
   "metadata": {},
   "source": [
    "* No proper names (Nb)\n",
    "* Total 100 words, 20 used definition from CWN, 80 from model generation. These words are all taken from evaluation set.\n",
    "* Among the generation items, 20 are nouns, 20 are verbs, 20 are adverbs, and 20 are others. \n",
    "* The word class composition is the same for the ones from CWN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1de9766-a6e5-4eae-ad22-9a4cbdb88030",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = list(ds_defgen[\"test\"])\n",
    "for x in eval_data:    \n",
    "    pos = x[\"tgt\"].split(\"。\")[0]\n",
    "    pos = \",\".join(x \n",
    "                   for x in pos.split(\",\")\n",
    "                   if x!=\"nom\")\n",
    "    if pos and pos == \"Nb\":\n",
    "        x[\"pos\"] = \"X\" # ignore\n",
    "    elif pos and pos[0] in \"DVN\":\n",
    "        x[\"pos\"] = pos[0]\n",
    "    else:\n",
    "        x[\"pos\"] = \"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b94b576c-125a-4843-9c44-4b2b037f2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = sorted(eval_data, key=lambda x: x[\"pos\"])\n",
    "grouped_data = list((grp, list(grp_iter)) \n",
    "                     for grp, grp_iter in groupby(eval_data, key=lambda x: x[\"pos\"])\n",
    "                     if grp!=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d86f89-f24f-405c-ac7b-3231017d1677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 432), ('N', 2801), ('O', 530), ('V', 4376)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], len(x[1])) for x in grouped_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7385de2-1141-4569-9e65-4ecdeaf635ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afce73e441604964bcfb91008bc02f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "rng = random.Random(12345)\n",
    "sampled = {\"D\": [], \"N\": [], \"V\": [], \"O\": []}\n",
    "pbar = tqdm(total=100)\n",
    "for pos, data in grouped_data:    \n",
    "    shuffle_data = data[:]\n",
    "    rng.shuffle(shuffle_data)\n",
    "    buf = sampled[pos]\n",
    "    for i in range(25):\n",
    "        pbar.update(1)\n",
    "        data_x = shuffle_data[i]\n",
    "        data_x[\"target\"] = cwn.from_sense_id(data_x[\"cwnid\"]).head_word\n",
    "        data_x[\"fillers\"] = [\n",
    "            cwn.from_sense_id(x[\"cwnid\"]).head_word \n",
    "            for x in shuffle_data[-i*4-4:-i*4-1]]\n",
    "        if i < 5:\n",
    "            data_x[\"from\"] = \"CWN\"\n",
    "            deftext = data_x[\"tgt\"].split(\"。\")[1]\n",
    "        else:\n",
    "            data_x[\"from\"] = \"vec4gloss\"\n",
    "            deftext = gen(data_x[\"src\"]).split(\"。\")[1]\n",
    "        \n",
    "        if not deftext.endswith(\"。\"):\n",
    "            deftext += \"。\"\n",
    "        deftext = deftext.translate(str.maketrans(\",.\", \"，。\"))\n",
    "        data_x[\"definition\"] = deftext\n",
    "        data_x[\"item_id\"] = f\"{pos}-{i:02d}\"\n",
    "        buf.append(data_x)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4cca9a-686d-419c-a65d-cd772ac9d90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 25), ('N', 25), ('V', 25), ('O', 25)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], len(x[1])) for x in sampled.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d376cd1-e603-441c-b1f7-3761eaab7043",
   "metadata": {},
   "source": [
    "## Make rate items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11b94a7e-ae16-44a5-93e5-517877de2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "rng_item = random.Random(12333)\n",
    "def make_items(entry_x):\n",
    "    item_x = {}\n",
    "    item_x[\"target\"] = entry_x[\"target\"]\n",
    "    item_x[\"pos\"] = entry_x[\"pos\"]\n",
    "    item_x[\"from\"] = entry_x[\"from\"]\n",
    "    item_x[\"item_id\"] = entry_x[\"item_id\"]\n",
    "    candids = entry_x[\"fillers\"] + [entry_x[\"target\"]]    \n",
    "    rng_item.shuffle(candids)\n",
    "    candids = [f\"{a}.{x}\" for a, x in zip(\"ABCD\", candids)]\n",
    "    item_x[\"candids\"] = \", \".join(candids)\n",
    "    item_x[\"definition\"] = entry_x[\"definition\"]\n",
    "    return item_x\n",
    "\n",
    "ent_iter = chain.from_iterable([sampled.values(), new_words.values()])\n",
    "rate_items = [make_items(x) for x in chain.from_iterable(ent_iter)]\n",
    "rng_item.shuffle(rate_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22d59c3-1576-4cab-a49b-d68369af585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pos</th>\n",
       "      <th>from</th>\n",
       "      <th>item_id</th>\n",
       "      <th>candids</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>鵲</td>\n",
       "      <td>N</td>\n",
       "      <td>CWN</td>\n",
       "      <td>N-03</td>\n",
       "      <td>A.事實, B.研, C.觀光客, D.鵲</td>\n",
       "      <td>以鵲為形象製成的人造物。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>刺進</td>\n",
       "      <td>V</td>\n",
       "      <td>ASBC</td>\n",
       "      <td>V-50</td>\n",
       "      <td>A.燃起, B.放生, C.刺進, D.與日俱增</td>\n",
       "      <td>物體表面或特定部位向外凸出。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>環球</td>\n",
       "      <td>O</td>\n",
       "      <td>ASBC</td>\n",
       "      <td>O-53</td>\n",
       "      <td>A.軍用, B.環球, C.公教, D.聯外</td>\n",
       "      <td>環繞太陽一周所需的時間。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>還</td>\n",
       "      <td>D</td>\n",
       "      <td>vec4gloss</td>\n",
       "      <td>D-12</td>\n",
       "      <td>A.還, B.悄悄, C.相形之下, D.如此一來</td>\n",
       "      <td>表事情尚未完成。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>以及</td>\n",
       "      <td>O</td>\n",
       "      <td>vec4gloss</td>\n",
       "      <td>O-21</td>\n",
       "      <td>A.從, B.經過, C.就, D.以及</td>\n",
       "      <td>連接並列的詞組，表做連接的事件同時成立。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>尚且</td>\n",
       "      <td>D</td>\n",
       "      <td>ASBC</td>\n",
       "      <td>D-51</td>\n",
       "      <td>A.未及, B.自古以來, C.尚且, D.百般</td>\n",
       "      <td>表動作或情況持續不變。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>中上</td>\n",
       "      <td>O</td>\n",
       "      <td>ASBC</td>\n",
       "      <td>O-54</td>\n",
       "      <td>A.像是, B.寬頻, C.沿著, D.中上</td>\n",
       "      <td>等級不在兩端的部份。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>絕非</td>\n",
       "      <td>D</td>\n",
       "      <td>vec4gloss</td>\n",
       "      <td>D-22</td>\n",
       "      <td>A.向來, B.一心一意, C.淺, D.絕非</td>\n",
       "      <td>表絕對不是。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>正</td>\n",
       "      <td>D</td>\n",
       "      <td>vec4gloss</td>\n",
       "      <td>D-06</td>\n",
       "      <td>A.另行, B.正, C.就近, D.勿</td>\n",
       "      <td>表順著特定對象進行後述事件。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>麻</td>\n",
       "      <td>N</td>\n",
       "      <td>CWN</td>\n",
       "      <td>N-00</td>\n",
       "      <td>A.誠, B.雜誌, C.蝶, D.麻</td>\n",
       "      <td>麻的味道，會使食用者暫時失去味覺。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target pos       from item_id                    candids  \\\n",
       "0        鵲   N        CWN    N-03      A.事實, B.研, C.觀光客, D.鵲   \n",
       "1       刺進   V       ASBC    V-50   A.燃起, B.放生, C.刺進, D.與日俱增   \n",
       "2       環球   O       ASBC    O-53     A.軍用, B.環球, C.公教, D.聯外   \n",
       "3        還   D  vec4gloss    D-12  A.還, B.悄悄, C.相形之下, D.如此一來   \n",
       "4       以及   O  vec4gloss    O-21       A.從, B.經過, C.就, D.以及   \n",
       "..     ...  ..        ...     ...                        ...   \n",
       "115     尚且   D       ASBC    D-51   A.未及, B.自古以來, C.尚且, D.百般   \n",
       "116     中上   O       ASBC    O-54     A.像是, B.寬頻, C.沿著, D.中上   \n",
       "117     絕非   D  vec4gloss    D-22    A.向來, B.一心一意, C.淺, D.絕非   \n",
       "118      正   D  vec4gloss    D-06       A.另行, B.正, C.就近, D.勿   \n",
       "119      麻   N        CWN    N-00        A.誠, B.雜誌, C.蝶, D.麻   \n",
       "\n",
       "               definition  \n",
       "0            以鵲為形象製成的人造物。  \n",
       "1          物體表面或特定部位向外凸出。  \n",
       "2            環繞太陽一周所需的時間。  \n",
       "3                表事情尚未完成。  \n",
       "4    連接並列的詞組，表做連接的事件同時成立。  \n",
       "..                    ...  \n",
       "115           表動作或情況持續不變。  \n",
       "116            等級不在兩端的部份。  \n",
       "117                表絕對不是。  \n",
       "118        表順著特定對象進行後述事件。  \n",
       "119     麻的味道，會使食用者暫時失去味覺。  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rate_df = pd.DataFrame.from_records(rate_items)\n",
    "rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef974394-cd0c-485b-999e-26737d11c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df.to_csv(\"../data/rating_materials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44691a-3011-45c1-9b1c-7264605bbf39",
   "metadata": {},
   "source": [
    "## Output Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9332a9-6cb6-4375-9867-15659eb7f16e",
   "metadata": {},
   "source": [
    "```\n",
    "..\\data\\rating_materials.csv 186be2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55a72275-6004-41de-88e7-0eb3aa21a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\rating_materials.csv 186be2\n"
     ]
    }
   ],
   "source": [
    "_ = check_hashes([\n",
    "    \"../data/rating_materials.csv\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5eb7b-9705-455d-a19f-52cb30f94c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
