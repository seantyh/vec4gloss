{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44f67d8-2f95-46c5-a584-3f3d01595f11",
   "metadata": {},
   "source": [
    "# Prepare Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661bf2ca-b8a7-47a8-8965-8ad5702defa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.append(\"../src\")\n",
    "if \"../../pyASBC/src\" not in sys.path:\n",
    "    sys.path.append(\"../../pyASBC/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af613c3b-6d89-43e7-8c93-6024ade42d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from itertools import islice, chain, groupby\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import MT5TokenizerFast\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import datasets\n",
    "\n",
    "from CwnGraph import CwnImage\n",
    "import vec4gloss\n",
    "from vec4gloss import check_hashes\n",
    "from vec4gloss import Vec4GlossModel\n",
    "from pyASBC import Asbc5Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad996d0b-4182-48d4-bbb8-33147a6cca9a",
   "metadata": {},
   "source": [
    "## Data dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df370cdb-8678-4308-b6ec-b837eb231873",
   "metadata": {},
   "source": [
    "```\n",
    "10.11 -> ..\\data\\defgen_dataset_cwn\\train\\dataset.arrow 65a56d\n",
    "20.21 -> ..\\data\\models\\vec4gloss-defgen-220629-1250\\pytorch_model.bin 9f894f\n",
    "(external) -> ..\\data\\asbc5_words_pos.pkl 70badc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a101b0d-1e45-4ecf-a818-b02e407f1223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\defgen_dataset_cwn\\train\\dataset.arrow 65a56d\n",
      "..\\data\\models\\vec4gloss-defgen-220629-1250\\pytorch_model.bin 9f894f\n",
      "..\\data\\asbc5_words_pos.pkl 70badc\n"
     ]
    }
   ],
   "source": [
    "vec4gloss_model_dir = \"../data/models/vec4gloss-defgen-220629-1250\"\n",
    "_ = check_hashes([\n",
    "    \"../data/defgen_dataset_cwn/train/dataset.arrow\",\n",
    "    vec4gloss_model_dir + \"/pytorch_model.bin\",\n",
    "    \"../data/asbc5_words_pos.pkl\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bfa651-97f8-49ef-a61e-84ed69f74b3b",
   "metadata": {},
   "source": [
    "## Loading resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8df1d5c-cff5-4ff6-bff2-d468f059af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/asbc5_words_pos.pkl\", \"rb\") as fin:\n",
    "    asbc_words = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d266e3-eaac-40df-94a6-11f5add4ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and \"GeForce\" not in torch.cuda.get_device_name():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f42cd71-0c3f-430a-b1d9-f2a148455950",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_defgen = datasets.load_from_disk(\"../data/defgen_dataset_cwn\")\n",
    "model = Vec4GlossModel.from_pretrained(vec4gloss_model_dir).to(device)\n",
    "tokenizer = MT5TokenizerFast.from_pretrained(vec4gloss_model_dir)\n",
    "gen = vec4gloss.gen_func(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55960220-8cd3-4a1b-903a-45631a53b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWN_VER = \"v.2022.06.21\"\n",
    "cwn = CwnImage.load(CWN_VER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ca527-01a4-4516-b2ea-810aa7df8f7c",
   "metadata": {},
   "source": [
    "## Prepare rating materials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15123cc-6820-4d49-90ee-77b2aab6a314",
   "metadata": {},
   "source": [
    "### New words from ASBC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cf9b0e-a49f-4eff-b1ed-08882b49d54f",
   "metadata": {},
   "source": [
    "* frequency > 10\n",
    "* no proper nouns (Nb)\n",
    "* only words composed of Chinese characters(U+4E00-U+9FFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48230bd-e8c7-4afe-84ba-301c99d49941",
   "metadata": {},
   "outputs": [],
   "source": [
    "asbc = Asbc5Corpus(\"../../pyASBC/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9afd72-8b1d-4e6f-a0f7-fd68a93f6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_example_sentence(target, pos):\n",
    "    for sent in asbc.iter_sentences():        \n",
    "        tgt_idx = [i for i, (w,p,_)\n",
    "                   in enumerate(sent)\n",
    "                   if w==target and p==pos]\n",
    "        if tgt_idx:            \n",
    "            tgt_idx = tgt_idx[0]\n",
    "            words = [x[0] for x in sent]\n",
    "            words[tgt_idx] = f\"<{target}>\"\n",
    "            return \"\".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24818e19-7638-4bab-b6c4-0304f17a6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_asbc = random.Random(14434)\n",
    "lemmas = set(cwn.get_all_lemmas().keys())\n",
    "chpat = re.compile(\"^[\\u4e00-\\u9fff]+$\")\n",
    "asbc_pos_list = {\"D\": [], \"N\": [], \"V\": [], \"O\": []}\n",
    "for (word, pos), freq in asbc_words.most_common():\n",
    "    if freq < 20: continue\n",
    "    if pos == \"Nb\": continue\n",
    "    if not chpat.match(word): continue\n",
    "    if word not in lemmas:\n",
    "        if pos and pos[0] in \"DVN\":\n",
    "            poscat = pos[0]\n",
    "        else:\n",
    "            poscat = \"O\"\n",
    "        asbc_pos_list[poscat].append((word, pos))\n",
    "for poscat in asbc_pos_list:\n",
    "    rng_asbc.shuffle(asbc_pos_list[poscat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8dca169-c244-459b-a8c1-f909cb8f2adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 285, 'N': 6396, 'V': 4032, 'O': 135}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(v) for k, v in asbc_pos_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb891bcf-1a6e-4e26-8863-0c9520212f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0fdaa6927f48c9afb20f55169c895f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_words = {\"D\": [], \"N\": [], \"V\": [], \"O\": []}\n",
    "pbar = tqdm(total=20)\n",
    "for poscat, pos_buf in new_words.items():\n",
    "    word_list = asbc_pos_list[poscat][::-1]\n",
    "    while len(pos_buf) < 5:        \n",
    "        pbar.update(1)\n",
    "        entry_x = {}\n",
    "        word, pos = word_list.pop()\n",
    "        entry_x[\"from\"] = \"ASBC\"\n",
    "        entry_x[\"pos\"] = poscat\n",
    "        entry_x[\"target\"] = word\n",
    "        entry_x[\"fillers\"] = [word_list.pop()[0] for _ in range(3)]\n",
    "        sent = find_example_sentence(word, pos)        \n",
    "        if not sent:\n",
    "            continue\n",
    "            \n",
    "        deftext = gen(sent).split(\"。\")[1]\n",
    "        if not deftext.endswith(\"。\"):\n",
    "            deftext += \"。\"\n",
    "        deftext = deftext.translate(str.maketrans(\",.\", \"，。\"))\n",
    "        entry_x[\"definition\"] = deftext\n",
    "        entry_x[\"item_id\"] = f\"{poscat}-{(len(pos_buf)+50):02d}\"\n",
    "        pos_buf.append(entry_x)        \n",
    "pbar.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827bd857-a125-4e34-9311-623d2f1db0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': {'from': 'ASBC',\n",
       "  'pos': 'D',\n",
       "  'target': '一窩蜂',\n",
       "  'fillers': ['何妨', '同聲', '方才'],\n",
       "  'definition': '比喻嗜好特定對象的怪獸。',\n",
       "  'item_id': 'D-50'},\n",
       " 'N': {'from': 'ASBC',\n",
       "  'pos': 'N',\n",
       "  'target': '明牌',\n",
       "  'fillers': ['西湖', '小生', '磚牆'],\n",
       "  'definition': '比喻在競爭中被淘汰的對象。',\n",
       "  'item_id': 'N-50'},\n",
       " 'V': {'from': 'ASBC',\n",
       "  'pos': 'V',\n",
       "  'target': '刺進',\n",
       "  'fillers': ['放生', '燃起', '與日俱增'],\n",
       "  'definition': '物體表面或特定部位向外凸出。',\n",
       "  'item_id': 'V-50'},\n",
       " 'O': {'from': 'ASBC',\n",
       "  'pos': 'O',\n",
       "  'target': '長足',\n",
       "  'fillers': ['麻辣', '英屬', '駐華'],\n",
       "  'definition': '比喻事件發展的基礎。',\n",
       "  'item_id': 'O-50'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v[0] for k, v in new_words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0026a2d2-7b70-4e7e-baa1-a80a634b56cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 5), ('N', 5), ('V', 5), ('O', 5)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], len(x[1])) for x in new_words.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e90629-a9c1-4f19-9c4f-bb54a10365fd",
   "metadata": {},
   "source": [
    "### Words in evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188353e7-0e8f-47f7-bee9-9049bb2e34e2",
   "metadata": {},
   "source": [
    "* No proper names (Nb)\n",
    "* Total 100 words, 20 used definition from CWN, 80 from model generation. These words are all taken from evaluation set.\n",
    "* Among the generation items, 20 are nouns, 20 are verbs, 20 are adverbs, and 20 are others. \n",
    "* The word class composition is the same for the ones from CWN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1de9766-a6e5-4eae-ad22-9a4cbdb88030",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = list(ds_defgen[\"test\"])\n",
    "for x in eval_data:                \n",
    "    pos = x[\"tgt\"].split(\"。\")[0]\n",
    "    pos = \",\".join(x \n",
    "                   for x in pos.split(\",\")\n",
    "                   if x!=\"nom\")\n",
    "    if pos and pos == \"Nb\":\n",
    "        x[\"pos\"] = \"X\" # ignore\n",
    "    elif not cwn.from_sense_id(x[\"cwnid\"]).head_word:\n",
    "        # empty words?\n",
    "        x[\"pos\"] = \"X\"\n",
    "    elif pos and pos[0] in \"DVN\":\n",
    "        x[\"pos\"] = pos[0]    \n",
    "    else:\n",
    "        x[\"pos\"] = \"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b94b576c-125a-4843-9c44-4b2b037f2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = sorted(eval_data, key=lambda x: x[\"pos\"])\n",
    "grouped_data = list((grp, list(grp_iter)) \n",
    "                     for grp, grp_iter in groupby(eval_data, key=lambda x: x[\"pos\"])\n",
    "                     if grp!=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d86f89-f24f-405c-ac7b-3231017d1677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 432), ('N', 2797), ('O', 529), ('V', 4368)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], len(x[1])) for x in grouped_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7385de2-1141-4569-9e65-4ecdeaf635ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6bc1b387c94aa0a487b9363fb4ffbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "rng = random.Random(12345)\n",
    "sampled = {\"D\": [], \"N\": [], \"V\": [], \"O\": []}\n",
    "pbar = tqdm(total=100)\n",
    "for pos, data in grouped_data:    \n",
    "    shuffle_data = data[:]\n",
    "    rng.shuffle(shuffle_data)\n",
    "    buf = sampled[pos]\n",
    "    for i in range(25):\n",
    "        pbar.update(1)\n",
    "        data_x = shuffle_data[i]\n",
    "        data_x[\"target\"] = cwn.from_sense_id(data_x[\"cwnid\"]).head_word\n",
    "        fillers = [\n",
    "            cwn.from_sense_id(x[\"cwnid\"]).head_word \n",
    "            for x in shuffle_data[-i*5-5:-i*5-1]]\n",
    "        data_x[\"fillers\"] = sorted(list(set(fillers)))[:3]\n",
    "        if i < 5:\n",
    "            data_x[\"from\"] = \"CWN\"\n",
    "            deftext = data_x[\"tgt\"].split(\"。\")[1]\n",
    "        else:\n",
    "            data_x[\"from\"] = \"vec4gloss\"\n",
    "            deftext = gen(data_x[\"src\"]).split(\"。\")[1]\n",
    "        \n",
    "        if not deftext.endswith(\"。\"):\n",
    "            deftext += \"。\"\n",
    "        deftext = deftext.translate(str.maketrans(\",.\", \"，。\"))\n",
    "        data_x[\"definition\"] = deftext\n",
    "        data_x[\"item_id\"] = f\"{pos}-{i:02d}\"\n",
    "        buf.append(data_x)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4cca9a-686d-419c-a65d-cd772ac9d90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 25), ('N', 25), ('V', 25), ('O', 25)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], len(x[1])) for x in sampled.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d376cd1-e603-441c-b1f7-3761eaab7043",
   "metadata": {},
   "source": [
    "## Make rate items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11b94a7e-ae16-44a5-93e5-517877de2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "rng_item = random.Random(12333)\n",
    "def make_items(entry_x, idx):\n",
    "    item_x = {}\n",
    "    candids = entry_x[\"fillers\"] + [entry_x[\"target\"]]    \n",
    "    rng_item.shuffle(candids)\n",
    "    options = [f\"{a}.{x}\" for a, x in zip(\"ABCD\", candids)]\n",
    "    tgt_idx = candids.index(entry_x[\"target\"])\n",
    "        \n",
    "    item_x[\"target\"] = entry_x[\"target\"]\n",
    "    item_x[\"ans\"] = \"ABCD\"[tgt_idx]\n",
    "    item_x[\"pos\"] = entry_x[\"pos\"]\n",
    "    item_x[\"from\"] = entry_x[\"from\"]\n",
    "    item_x[\"item_id\"] = entry_x[\"item_id\"]        \n",
    "    item_x[\"definition\"] = entry_x[\"definition\"]\n",
    "    item_x[\"options\"] = \" \".join(options)\n",
    "    return item_x\n",
    "\n",
    "ent_iter = chain.from_iterable([sampled.values(), new_words.values()])\n",
    "rate_items = [make_items(x, idx) for idx, x in enumerate(chain.from_iterable(ent_iter))]\n",
    "rng_item.shuffle(rate_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22d59c3-1576-4cab-a49b-d68369af585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rate_df = pd.DataFrame.from_records(rate_items)\n",
    "rate_df.index = np.arange(1, len(rate_df)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9eb482e-863c-4dda-8edc-1bf95acd10ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <th>D</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASBC</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CWN</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vec4gloss</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target            \n",
       "pos            D   N   O   V\n",
       "from                        \n",
       "ASBC           5   5   5   5\n",
       "CWN            5   5   5   5\n",
       "vec4gloss     20  20  20  20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_df.pivot_table(values=[\"target\"], index=[\"from\"], columns=[\"pos\"], aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52f897a8-1601-44b6-b8f1-ab58f8bdc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rate_df.apply(lambda x: x.target in x.options, axis=1).all() # every options has target\n",
    "# no duplicated options\n",
    "assert rate_df.apply(lambda x: len(set(x.options.translate(str.maketrans(\"\", \"\", \"ABCD.\")).split()))==4, axis=1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef974394-cd0c-485b-999e-26737d11c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df.to_csv(\"../data/rating_materials.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44691a-3011-45c1-9b1c-7264605bbf39",
   "metadata": {},
   "source": [
    "## Output Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9332a9-6cb6-4375-9867-15659eb7f16e",
   "metadata": {},
   "source": [
    "```\n",
    "..\\data\\rating_materials.csv a750c9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55a72275-6004-41de-88e7-0eb3aa21a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\rating_materials.csv a750c9\n"
     ]
    }
   ],
   "source": [
    "_ = check_hashes([\n",
    "    \"../data/rating_materials.csv\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5eb7b-9705-455d-a19f-52cb30f94c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
