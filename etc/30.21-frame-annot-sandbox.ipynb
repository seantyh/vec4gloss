{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4706806-a00d-4050-9b2d-af0b789c173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3b387c-14bc-42f0-9fad-becd7698459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import MT5TokenizerFast\n",
    "\n",
    "from CwnGraph import CwnImage\n",
    "import vec4gloss\n",
    "from vec4gloss import check_hashes\n",
    "from vec4gloss import Vec4GlossModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e950b7-c21e-407e-9c78-3246ee1465c1",
   "metadata": {},
   "source": [
    "## Data dependencies\n",
    "```\n",
    "..\\data\\annotation.json 2ed250\n",
    "..\\data\\models\\vec4gloss-defgen-220629-1250\\pytorch_model.bin 9f894f\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988179fd-ce73-4741-b434-b93c5bf9dc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\annotation.json 2ed250\n",
      "..\\data\\models\\vec4gloss-defgen-220629-1250\\pytorch_model.bin 9f894f\n"
     ]
    }
   ],
   "source": [
    "vec4gloss_model_dir = \"../data/models/vec4gloss-defgen-220629-1250\"\n",
    "_ = check_hashes([\n",
    "    \"../data/annotation.json\",\n",
    "    vec4gloss_model_dir + \"/pytorch_model.bin\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e2c7f-2493-464b-80a8-11eef946e23a",
   "metadata": {},
   "source": [
    "## Loading resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab82139-ddb9-4e57-99ef-06d879707307",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_data = json.loads(Path(\"../data/annotation.json\").read_text(encoding=\"UTF-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0588b40e-8cae-4c5a-8dae-a29c12258b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,\n",
       " {'sense_id': 3048001,\n",
       "  'head_word': '沿街',\n",
       "  'POS': 'D',\n",
       "  'definition': '表同一事件在經過的街道中重複發生。',\n",
       "  'event_role': 'agent',\n",
       "  'schemas': [{'type': 'event', 'start': 1, 'end': 5},\n",
       "   {'type': 'scope', 'start': 5, 'end': 6},\n",
       "   {'type': 'place', 'start': 6, 'end': 11},\n",
       "   {'type': 'scope', 'start': 11, 'end': 12},\n",
       "   {'type': 'mod', 'start': 12, 'end': 14},\n",
       "   {'type': 'action', 'start': 14, 'end': 16}]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_data), annot_data[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f727e5ae-c9ca-4908-832a-ebbb353032ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "## Loading modem\n",
    "use_cuda = torch.cuda.is_available() and \"GeForce\" not in torch.cuda.get_device_name()\n",
    "device = \"cuda\" if use_cuda else \"cpu\"    \n",
    "print(\"Using\", device)\n",
    "\n",
    "model = Vec4GlossModel.from_pretrained(vec4gloss_model_dir).to(device)\n",
    "tokenizer = MT5TokenizerFast.from_pretrained(vec4gloss_model_dir)\n",
    "gen = vec4gloss.gen_func(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6cc531a-05c5-418a-afe3-9807892cc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWN_VER = \"v.2022.06.21\"\n",
    "cwn = CwnImage.load(CWN_VER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cdb3b0-984b-4bc9-8317-f8c4e96390e5",
   "metadata": {},
   "source": [
    "## Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5fc48c-1b3f-4b9e-a138-0efed72ee296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5045001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_data[0][\"sense_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a00d723-c268-4d11-8316-a40a1dd4f81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "就\n",
      "Tgt: D。表後述事件在很短的時間內完成。\n",
      "Gen: D。表後述事件緊接著前述事件發生。\n"
     ]
    }
   ],
   "source": [
    "annot_x = annot_data[5]\n",
    "examples = cwn.from_sense_id(\"{:08d}\".format(annot_x[\"sense_id\"])).examples\n",
    "enc_vecs = []\n",
    "for ex in examples:\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            enc_vecs.append(vec4gloss.extract_encoder_vector(ex, tokenizer, model))\n",
    "    except AssertionError:\n",
    "        pass\n",
    "\n",
    "mean_vec = torch.cat(enc_vecs).mean(0, keepdim=True)\n",
    "print(annot_x[\"head_word\"])\n",
    "print(\"Tgt: {}。{}\".format(annot_x[\"POS\"], annot_x[\"definition\"]))\n",
    "print(\"Gen:\", vec4gloss.decode_vector(mean_vec, tokenizer, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74c5ee1-c9e4-453b-8a01-a6ccb8b8038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<CwnSense[04000809](而，Cbb): 表後述事件緊接著前述事件發生。>,\n",
       " <CwnSense[04026904](便是，D): 表後述事件緊接著前述事件發生。>,\n",
       " <CwnSense[05198303](就，D): 表後述事件緊接著前述事件發生。>,\n",
       " <CwnSense[07114803](便，D): 表後述事件緊接著前述事件發生。>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwn.find_senses(definition=\"表後述事件緊接著前述事件發生。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efb1d08-bf90-4571-b146-c2fdf886c369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,    431,    306,   7130,   7605,  53823,  25182, 179158,  11522,\n",
       "          17355,   2884,  53823,  25182,  31875,   3355,    306,      1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(decoder_encoder_vector=mean_vec, bos_token_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9f4396-865f-47ef-b0af-38a9418e83f2",
   "metadata": {},
   "source": [
    "## Manual unroll the generation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7b4e4a-1e02-4655-b8af-d599000bbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out0 = model(decoder_encoder_vector=mean_vec, decoder_input_ids=torch.tensor([[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15586c94-1034-4734-96ad-1d5592762d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[431]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0.logits.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aef2393-468f-4996-b20d-8c63b62da146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bea014d-aa3c-4e05-aea5-f074e6dbb7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(out0.logits.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7afe770-1b96-4d61-889b-60d25bbf6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = model(decoder_encoder_vector=mean_vec, \n",
    "             decoder_input_ids=torch.tensor([[431]]), \n",
    "             past_key_values=out0.past_key_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb495e46-b639-40b8-aa2c-e41f8ac7febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[306]]) ['。']\n"
     ]
    }
   ],
   "source": [
    "print(out1.logits.argmax(-1), tokenizer.batch_decode(out1.logits.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdbf58ab-bc11-4d4e-aac4-c6d145786ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = model(decoder_encoder_vector=mean_vec, \n",
    "             decoder_input_ids=torch.tensor([[306]]), \n",
    "             past_key_values=out1.past_key_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5422cf0f-2a4b-48a3-8823-fdfcb416159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7130]]) ['表']\n"
     ]
    }
   ],
   "source": [
    "print(out2.logits.argmax(-1), tokenizer.batch_decode(out2.logits.argmax(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9966a1-da06-435b-9530-159db977bd7b",
   "metadata": {},
   "source": [
    "### See how the same input_ids results in different output with no past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5520d8aa-201d-4377-9f5f-88dfb0096458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]]) ['</s>']\n"
     ]
    }
   ],
   "source": [
    "out2a = model(decoder_encoder_vector=mean_vec, \n",
    "             decoder_input_ids=torch.tensor([[306]]))\n",
    "print(out2a.logits.argmax(-1), tokenizer.batch_decode(out2a.logits.argmax(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff337f-6e93-4e26-b72c-2f0fc094d953",
   "metadata": {},
   "source": [
    "### Continue generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7c2ef52-9388-4fa6-bd45-033cbe225c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = model(decoder_encoder_vector=mean_vec, \n",
    "             decoder_input_ids=torch.tensor([[7130]]), \n",
    "             past_key_values=out2.past_key_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d272e9fd-dc65-43e0-816d-644464a5ca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7605]]) ['後']\n"
     ]
    }
   ],
   "source": [
    "print(out3.logits.argmax(-1), tokenizer.batch_decode(out3.logits.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d256ce5a-ce0f-451f-a129-f14e32af2642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53823]]) ['述']\n"
     ]
    }
   ],
   "source": [
    "out4 = model(decoder_encoder_vector=mean_vec, \n",
    "             decoder_input_ids=torch.tensor([[7605]]), \n",
    "             past_key_values=out3.past_key_values)\n",
    "print(out4.logits.argmax(-1), tokenizer.batch_decode(out4.logits.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a54bd20-65a2-4923-9f45-d7d6eac3cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53823]]) ['述']\n"
     ]
    }
   ],
   "source": [
    "## is 後 have to be followed by \"述\"??\n",
    "out4a = model(decoder_encoder_vector=mean_vec, \n",
    "             decoder_input_ids=torch.tensor([[7605]]))\n",
    "print(out4a.logits.argmax(-1), tokenizer.batch_decode(out4a.logits.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f4ce2ec-5ce2-4341-902d-9a4da2cdfa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7519, 22879, 11522,   493, 53823])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out4a.logits.argsort().squeeze()[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7337db87-46c8-41a9-982e-4343fde80787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'再完成接的述'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what are other choices?\n",
    "tokenizer.decode(out4a.logits.argsort().squeeze()[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d035fdf-5a97-4404-b4d8-6805ad82331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out4 = model(decoder_encoder_vector=mean_vec, \n",
    "             decoder_input_ids=torch.tensor([[7605, 7606]]), \n",
    "             decoder_attention_mask=torch.tensor([[0,0,1,0,0,1]]),\n",
    "             past_key_values=out3.past_key_values, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7f47c91-eb01-4954-8a3d-69ab6c49aaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out4.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7da927eb-0533-42c8-96fc-33ea1059562f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out4.cross_attentions[0][0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "383fe996-62c7-4f7e-8449-4e09e1c8729b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 4, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3.past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26b90045-57b2-4a1b-9946-b279935bd473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 2, 6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dec_att = out4.decoder_attentions[0].detach().cpu()\n",
    "dec_att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b30eb4ff-57d9-4c36-b7b5-66e24e2cdc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b687e04580>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dec_att[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60ea2e3a-1c9d-4fb3-93ba-74569fac9904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.9535, 0.0000, 0.0000, 0.0465]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_att[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa9819-ea8c-4af0-9847-ab9f34f93874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
