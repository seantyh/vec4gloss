{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254163df-d703-433b-905b-b29ef6450d88",
   "metadata": {},
   "source": [
    "# Decoding Logits - Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95881a3-099e-4d42-af89-84af18de1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051d63a6-dee0-45eb-941f-3de815f47dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import MT5TokenizerFast\n",
    "from vec4gloss import check_hashes\n",
    "from vec4gloss import Vec4GlossModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6667235-fb01-4c60-8900-2b10200bde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_defgen = datasets.load_from_disk(\"../data/defgen_dataset_cwn\")\n",
    "vec4gloss_model_dir = \"../data/models/vec4gloss-defgen-220628-1546\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a042ea4-1339-42ee-843c-bbce498fb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MT5TokenizerFast.from_pretrained(vec4gloss_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37942b76-3827-4283-bb66-d7b161ee8780",
   "metadata": {},
   "source": [
    "## Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa2bab9-b020-412b-8019-1bc1f83a3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "\n",
    "def get_marked_pos(text):\n",
    "    assert text.count(\"<\") == text.count(\">\") == 1\n",
    "    s, e = text.index(\"<\")+1, text.index(\">\")    \n",
    "    assert s != e\n",
    "    return s, e\n",
    "\n",
    "def add_marked_pos(ex):\n",
    "    pos = get_marked_pos(ex[\"src\"])\n",
    "    return {\"decoder_start_markers\": pos[0], \"decoder_end_markers\": pos[1]}\n",
    "\n",
    "def preprocess_fn(batch):    \n",
    "    src_batch = tokenizer(batch[\"src\"], \n",
    "                          max_length=max_length, truncation=True)\n",
    "    start_markers = [src_batch.char_to_token(bi,s) \n",
    "                     for bi, s in enumerate(batch[\"decoder_start_markers\"])]\n",
    "    end_markers = [src_batch.char_to_token(bi,e) \n",
    "                   for bi, e in enumerate(batch[\"decoder_end_markers\"])]\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        tgt_batch = tokenizer(batch[\"tgt\"],\n",
    "                              max_length=max_length, truncation=True)        \n",
    "        \n",
    "    return {\n",
    "        **src_batch, \n",
    "        \"decoder_start_markers\": start_markers,\n",
    "        \"decoder_end_markers\": end_markers,\n",
    "        \"labels\": tgt_batch[\"input_ids\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bc6427-289b-4cd9-9048-6c3eae2a440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../data/defgen_dataset_cwn/train\\cache-73645a22723c5115.arrow\n",
      "Loading cached processed dataset at ../data/defgen_dataset_cwn/test\\cache-79eff688f816c6ef.arrow\n",
      "Loading cached processed dataset at ../data/defgen_dataset_cwn/train\\cache-7d7b0c80d6938a82.arrow\n",
      "Loading cached processed dataset at ../data/defgen_dataset_cwn/test\\cache-51609cdc52b73bd9.arrow\n"
     ]
    }
   ],
   "source": [
    "drop_columns = [\"cwnid\", \"src\", \"tgt\"]\n",
    "ds_defgen = (ds_defgen.map(add_marked_pos)\n",
    "             .map(preprocess_fn, batched=True, remove_columns=drop_columns))\n",
    "train_ds = ds_defgen[\"train\"]\n",
    "test_ds = ds_defgen[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db4fd9-90bf-4cac-b3e1-89e5d047e8e5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3ff1fd-dfb4-48ed-9144-642941bffc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "model = Vec4GlossModel.from_pretrained(vec4gloss_model_dir)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b7f3a3-e819-461e-939f-c2430b2ce08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cuda = torch.Generator()\n",
    "g_cuda.manual_seed(211321)\n",
    "loader = DataLoader(train_ds, batch_size=2, collate_fn=data_collator, shuffle=True, generator=g_cuda)\n",
    "batches = list(islice(loader, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5413304b-cad0-4b32-82b3-f15832500840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VC。模仿或照原樣重製他人的創意當作自己的。</s>',\n",
       " 'Nc。美術館的建築物及建築物所在的位置。</s><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels\n",
    "batch = batches[0]\n",
    "tokenizer.batch_decode(torch.where(batch[\"labels\"]>=0, batch[\"labels\"], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afe7de77-aed5-4e0e-bf52-e1b6d7f4a459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VC。比仿特定仿原來的的複的的文字新。作特定作品</s>', 'Nc。美術館的建築物及建築物所在的位置。</s></s> N N N N']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## direct decoding settings\n",
    "with torch.no_grad():    \n",
    "    batch = batches[0]\n",
    "    out = model(**batch)\n",
    "tokenizer.batch_decode(out.logits.argmax(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5dce11-b4aa-4510-86b6-4bc23d94b7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> VC。比喻將資料依照特定格式複製。</s>', '<pad> Nc。美術館的建築物及建築物所在的位置。</s>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## generation setting\n",
    "dbg = {}\n",
    "batch = batches[0]\n",
    "gen_batch = {k:v for k, v in batch.items() if k not in (\"labels\", \"decoder_input_ids\")}\n",
    "tokenizer.batch_decode(model.generate(**gen_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e20bd319-14c9-41ae-9e05-190ed21f609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genout = model.generate(**gen_batch, return_dict_in_generate=True, \n",
    "                        output_scores=True, output_hidden_states=True, \n",
    "                        output_attentions=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dde953b5-949f-40e9-a549-67ad4eb0979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sequences',\n",
       " 'scores',\n",
       " 'encoder_attentions',\n",
       " 'encoder_hidden_states',\n",
       " 'decoder_attentions',\n",
       " 'cross_attentions',\n",
       " 'decoder_hidden_states']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(genout.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7180d599-39f4-47e2-bc79-37d90838894d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VC。比喻將資料依照特定格式複製。</s>', 'Nc。美術館的建築物及建築物所在的位置。</s>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(torch.vstack([genout.scores[i].argmax(1) for i in range(len(genout.scores))]).permute(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "851463b3-ce9d-4240-af2d-ef37917fb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "intext = \"我們<上>山途中欣賞沿途風景。\"\n",
    "vbatch = tokenizer(intext, return_tensors=\"pt\")\n",
    "s,e = get_marked_pos(intext)\n",
    "s = vbatch.char_to_token(s)\n",
    "e = vbatch.char_to_token(e)\n",
    "vbatch[\"decoder_start_markers\"] = torch.tensor([s])\n",
    "vbatch[\"decoder_end_markers\"] = torch.tensor([e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d13a5864-ab40-4714-b0e0-bdd9390da383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> VCL。往高處移動。</s>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgenout = model.generate(**vbatch, max_length=30, \n",
    "                         return_dict_in_generate=True,\n",
    "                         output_scores=True, output_hidden_states=True, \n",
    "                        output_attentions=True)\n",
    "tokenizer.batch_decode(vgenout.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e07aed-a7d6-4e14-8718-839817713df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sequences',\n",
       " 'scores',\n",
       " 'encoder_attentions',\n",
       " 'encoder_hidden_states',\n",
       " 'decoder_attentions',\n",
       " 'cross_attentions',\n",
       " 'decoder_hidden_states']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vgenout.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0040a9a-5c5b-47c5-8831-5be2189c0c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this is what I expect if decoding only uses a single vector\n",
    "## It's a tuple(gen length) of tuple (decoder layers) of tensor\n",
    "## (batch_size, num_heads, sequence_length, sequence_length)\n",
    "vgenout.cross_attentions[4][7].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec3efa-6845-452a-a467-5de51c9cc09b",
   "metadata": {},
   "source": [
    "## split the encoder decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "112f5933-46d0-47de-996e-6e2cfa863400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VCL。往高處移動。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_encoder_vector(intext, tokenizer, model):    \n",
    "    vbatch = tokenizer(intext, return_tensors=\"pt\")\n",
    "    s,e = get_marked_pos(intext)   \n",
    "    s = vbatch.char_to_token(s)\n",
    "    e = vbatch.char_to_token(e)\n",
    "    vbatch[\"decoder_start_markers\"] = torch.tensor([s])\n",
    "    vbatch[\"decoder_end_markers\"] = torch.tensor([e])\n",
    "    encoder = model.get_encoder()\n",
    "    enc_out = encoder(\n",
    "            input_ids=vbatch[\"input_ids\"], \n",
    "            attention_mask=vbatch[\"attention_mask\"])\n",
    "    enc_vec = enc_out.last_hidden_state[[0],s:e,:] \\\n",
    "                     .mean(1, keepdim=True)\n",
    "    return enc_vec\n",
    "\n",
    "def decode_vector(vec, tokenizer, model, max_length=50):\n",
    "    vgenout = model.generate(decoder_encoder_vector=vec, bos_token_id=0, max_length=max_length)\n",
    "    return tokenizer.batch_decode(vgenout[:, 1:-1])[0]\n",
    "enc_vec = extract_encoder_vector(\"我們<上>山途中欣賞沿途風景。\", tokenizer, model)\n",
    "decode_vector(enc_vec, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c59d7-80fd-4bd5-9568-7d49e93d512a",
   "metadata": {},
   "source": [
    "## Morphing vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9d0c54a-14d8-477d-bd49-c9b935e053f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 VCL。往高處移動。\n",
      "0.20 VCL。從參考位置的外面移到參考位置的裡面。\n",
      "0.40 VCL。從參考位置的外面移到參考位置的裡面。\n",
      "0.60 nom,VA。進行餐飲活動。\n",
      "0.80 nom,VA。人們在約定俗成的固定時間內吃正餐。\n",
      "1.00 nom,VA。人們在約定俗成的固定時間內吃正餐。\n"
     ]
    }
   ],
   "source": [
    "enc_vec1 = extract_encoder_vector(\"我們<上>山途中欣賞沿途風景。\", tokenizer, model)\n",
    "enc_vec2 = extract_encoder_vector(\"我們在山裡<野餐>。\", tokenizer, model)\n",
    "delta = enc_vec2 - enc_vec1\n",
    "for i in np.arange(0, 1.01, 0.2):\n",
    "    print(f\"{i:.2f}\", decode_vector(enc_vec1+delta*i, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc2796a3-c351-4391-8646-fefab409168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 D。表突然出現在腦海中。\n",
      "0.20 D。表突然出現在腦海中。\n",
      "0.40 VH。形容突然出現在螢幕上。\n",
      "0.60 VH。形容特定對象沒有被使用。\n",
      "0.80 VH。形容比喻特定對象沒有被使用。\n",
      "1.00 VH。形容比喻特定對象沒有被使用。\n"
     ]
    }
   ],
   "source": [
    "enc_vec1 = extract_encoder_vector(\"我們上山時，天<突然>下起了大雪。\", tokenizer, model)\n",
    "enc_vec2 = extract_encoder_vector(\"為什麼我的留言板是<空>的？\", tokenizer, model)\n",
    "delta = enc_vec2 - enc_vec1\n",
    "for i in np.arange(0, 1.01, 0.2):\n",
    "    print(f\"{i:.2f}\", decode_vector(enc_vec1+delta*i, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0718447e-ebf5-4cd6-a1fd-d93b4fd7a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 Na。植物名,薔薇科花屬,葉卵形,花瓣五片,花瓣五片,花瓣五片,花瓣五片,花瓣五片,花瓣五片,花瓣五\n",
      "0.20 Na。植物名,薔薇科花屬,葉卵形,花瓣五片,花瓣五片,花瓣五片,花瓣五片,花瓣五片,花瓣五片,花瓣五\n",
      "0.40 Na。以花為形象製成的人造物。\n",
      "0.60 Na。筆畫的一種,由左往右的筆畫。\n",
      "0.80 Na。筆畫的一種,由左往右的筆畫。\n",
      "1.00 Na。筆畫的一種,由左往右的筆畫。\n"
     ]
    }
   ],
   "source": [
    "enc_vec1 = extract_encoder_vector(\"那是一位嬌豔如<花>的少女。\", tokenizer, model)\n",
    "enc_vec2 = extract_encoder_vector(\"以動畫方式慢速地顯示字母的每一<筆>一劃。\", tokenizer, model)\n",
    "delta = enc_vec2 - enc_vec1\n",
    "for i in np.arange(0, 1.01, 0.2):\n",
    "    print(f\"{i:.2f}\", decode_vector(enc_vec1+delta*i, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4539c736-4217-4078-bd5a-399dbb582728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 Na。哺乳類動物,偶蹄,腳短,身體肥胖,為主要用於食用的家畜。\n",
      "0.20 Na。以狗為形象製成的人造物。\n",
      "0.40 Na。以狗為形象製成的人造物。\n",
      "0.60 VC。用手或手持工具捕捉後述對象。\n",
      "0.80 VC。用手或手持工具捕捉後述對象。\n",
      "1.00 VC。用手或手持工具捕捉後述對象。\n"
     ]
    }
   ],
   "source": [
    "enc_vec1 = extract_encoder_vector(\"昨天我的<貓>抓了三隻老鼠。\", tokenizer, model)\n",
    "enc_vec2 = extract_encoder_vector(\"昨天我的貓<抓>了三隻老鼠。\", tokenizer, model)\n",
    "delta = enc_vec2 - enc_vec1\n",
    "for i in np.arange(0, 1.01, 0.2):\n",
    "    print(f\"{i:.2f}\", decode_vector(enc_vec1+delta*i, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cbaf2-93e6-44ee-862c-adc197c6eb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1895b90-2dc4-44c8-a607-e5b1fe29b805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
